# test_runnable



{
    "tabnine.experimentalAutoImports": true,
    "codellm.provider": "ollama",
    "codellm.ollama.url": "http://192.168.0.2:11434",
    "editor.inlineSuggest.suppressSuggestions": true,
    "telemetry.telemetryLevel": "off",
	"cody.autocomplete.advanced.provider": "experimental-ollama",
	"cody.autocomplete.experimental.ollamaOptions": {
  	"url": "http://192.168.0.2:11434",
  	"model": "codellama:13b"
	},
    "cody.experimental.ollamaChat": true,
    "cody.internal.unstable": true,
    "cody.autocomplete.triggerDelay": 1,
    "cody.telemetry.level": "off",
    "cody.net.proxy.skipCertValidation": true,
    "cody.dev.models": [    {
        "provider": "ollama",
        "model": "codellama:13b",
        "apiEndpoint": "http://192.168.0.2:11434"
      },
      {
        "provider": "ollama",
        "model": "gemma2:latest",
        "apiEndpoint": "http://192.168.0.2:11434"
      },
      {
        "provider": "ollama",
        "model": "lamma2:13b",
        "apiEndpoint": "http://192.168.0.2:11434"
      },
      {
        "provider": "ollama",
        "model": "lamma3.1:latest",
        "apiEndpoint": "http://192.168.0.2:11434"
      },
      {
        "provider": "ollama",
        "model": "llama3.2:latest",
        "apiEndpoint": "http://192.168.0.2:11434"
      },
      {
        "provider": "ollama",
        "model": "mistral-nemo:latest",
        "apiEndpoint": "http://192.168.0.2:11434"
      },
      {
        "provider": "ollama",
        "model": "qwen2.5-coder:14b",
        "apiEndpoint": "http://192.168.0.2:11434"
      },
      {
        "provider": "ollama",
        "model": "qwen2.5-coder:7b",
        "apiEndpoint": "http://192.168.0.2:11434"
      },
      {
        "provider": "ollama",
        "model": "llama3:latest",
        "apiEndpoint": "http://192.168.0.2:11434"
      }
    
    ]
}
